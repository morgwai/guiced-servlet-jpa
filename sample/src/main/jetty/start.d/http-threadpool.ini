--module=http
--module=threadpool

jetty.http.host=0.0.0.0
jetty.http.port=8080

## Number of threads performing TCP accept operation. Makes no sense to set it to a number greater
## than number of cores available.
## By default, Jetty never sets it to more than 4 which may be suboptimal on machines with big
## number of cores:
## https://github.com/eclipse/jetty.project/blob/jetty-9.4.35.v20201120/jetty-server/src/main/java/org/eclipse/jetty/server/AbstractConnector.java#L225
## https://github.com/eclipse/jetty.project/issues/1464#issuecomment-293694115
## As Jetty manual says "The standard rule of thumb for the number of Accepters to configure is one
## per CPU on a given machine": https://www.eclipse.org/jetty/documentation/jetty-9/#high-load
jetty.http.acceptors=4

## Number of threads polling/selecting through accepted connections and dispatching the requests to
## servlets. Each accepted connection is assigned in a round-robin manner to one selector. Each
## selector has a limit of 64k connections it can select among. Unless your server needs to deal
## with a huge number of long lasting, mostly idle connections, setting this to the number of cores
## should be more than sufficient.
## By default Jetty never sets it to more than a half of the number of cores:
## https://github.com/eclipse/jetty.project/blob/bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb/jetty-io/src/main/java/org/eclipse/jetty/io/SelectorManager.java#L79
jetty.http.selectors=4

## For server with http/1.1 connector only, Jetty reserves
## jetty.http.selectors + jetty.http.selectors + jetty.threadPool.reservedThreads
## for it's internal purposes (with ssl enabled for https and/or http/2, add also
## jetty.ssl.acceptors and jetty.ssl.selectors to the above).
## Optimal performance for servlets performing all time consuming operations asynchronously on
## on dedicated threadPools requires the above formula + number of cores.
##
## WARNING: not setting this to something considerably higher than the above formula (as it is done
## below for demo purposes), means that if your servlets perform even a single blocking operation
## on the main threadPool when handling requests, the *SERVER* *WILL* *MELT* *INSTANTLY*.
## It is generally much better idea to set it to something *way* higher and get alerted if the
## actual number of threads exceeds the above formula. This way investigation of the reason for the
## growing number of threads can be done while the server is still able to serve clients (growing
## number of threads will affect mostly just the memory footprint).
## See the links provided in http.ini file for more info on threadPool size tuning.
jetty.threadPool.maxThreads=12
jetty.threadPool.minThreads=12

## Number of reserved threads (-1 for heuristic)
jetty.threadPool.reservedThreads=0

## Whether to Output a Detailed Dump
jetty.threadPool.detailedDump=true

## Read more about tuning acceptor, selector and threadPool size numbers:
## https://www.eclipse.org/lists/jetty-users/msg04750.html
## https://support.sonatype.com/hc/en-us/articles/360000744687-Understanding-Eclipse-Jetty-9-4-8-Thread-Allocation
## https://webtide.com/eat-what-you-kill/
## https://webtide.com/thread-starvation-with-eat-what-you-kill-2/
